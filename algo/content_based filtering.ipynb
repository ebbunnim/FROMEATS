{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "import io\n",
    "\n",
    "\n",
    "store_columns = (\n",
    "    \"store_name\",\n",
    "    \"branch\",\n",
    "    \"area\",\n",
    "    \"tel\",\n",
    "    \"address\",\n",
    "    \"latitude\",\n",
    "    \"longitude\",\n",
    "    \"category\",\n",
    "    \"review_cnt\",\n",
    "    \"big_cate\",\n",
    "    \"mean_score\",\n",
    "    \"store\",\n",
    "    \"user\",\n",
    "    \"score\",\n",
    "    \"lifestyle\",\n",
    "    \"ratio\",\n",
    "    \"map_lifestyle\",\n",
    "    \"detail_lifestyle\"\n",
    ")\n",
    "\n",
    "data = []  # 음식점 테이블\n",
    "with open('../data/lifestylegroup_userscore.csv') as f:\n",
    "    for row in csv.DictReader(f):\n",
    "        data.append(row)\n",
    "\n",
    "stores = json.dumps(data)\n",
    "\n",
    "stores = []  # 음식점 테이블\n",
    "\n",
    "for d in data:\n",
    "\n",
    "    # review_cnt = \n",
    "    stores.append(\n",
    "        [\n",
    "            d[\"store_name\"],\n",
    "            d[\"branch\"],\n",
    "            d[\"area\"],\n",
    "            d[\"tel\"],\n",
    "            d[\"address\"],\n",
    "            d[\"latitude\"],\n",
    "            d[\"longitude\"],\n",
    "            d[\"category\"],\n",
    "            d[\"review_cnt\"],\n",
    "            d[\"big_cate\"],\n",
    "            d[\"mean_score\"],\n",
    "            d[\"store\"],\n",
    "            d[\"lifestyle\"],\n",
    "            d[\"ratio\"],\n",
    "            d[\"map_lifestyle\"],\n",
    "            d[\"detail_lifestyle\"]\n",
    "        ]\n",
    "    )\n",
    "\n",
    "store_new = pd.DataFrame(data=stores, columns=store_columns)\n",
    "\n",
    "print(store_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store_new.dtypes\n",
    "store_new[\"store\"].isnull()\n",
    "# store_new[\"store\"] = stores[\"store\"].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "DATA_DIR = \"../data\"\n",
    "DATA_FILE = os.path.join(DATA_DIR, \"data.json\")\n",
    "DUMP_FILE = os.path.join(DATA_DIR, \"dump.pkl\")\n",
    "\n",
    "store_columns = (\n",
    "    \"id\",  # 음식점 고유번호\n",
    "    \"store_name\",  # 음식점 이름\n",
    "    \"branch\",  # 음식점 지점 여부\n",
    "    \"area\",  # 음식점 위치\n",
    "    \"tel\",  # 음식점 번호\n",
    "    \"address\",  # 음식점 주소\n",
    "    \"latitude\",  # 음식점 위도  # 위치기반 음식점 추천할 때 사용\n",
    "    \"longitude\",  # 음식점 경도  # 위치기반 음식점 추천할 때 사용\n",
    "    \"category\",  # 음식점 카테고리\n",
    "    \"review_cnt\",  # 리뷰 갯수\n",
    ")\n",
    "\n",
    "menu_colums = (\n",
    "    \"store\",  # 음식점 고유번호\n",
    "    \"menu\",  # 메뉴 이름\n",
    "    \"price\",  # 메뉴 가격\n",
    ")\n",
    "\n",
    "hour_colums = (\n",
    "    \"type\",  # 영업시간 종류\n",
    "    \"week_type\",  # 주단위 종류\n",
    "    \"store\",  # 음식점 고유번호\n",
    "    \"mon\",  # 월요일 포함유무\n",
    "    \"tue\",  # 화요일 포함유무\n",
    "    \"wed\",  # 수요일 포함유무\n",
    "    \"thu\",  # 목요일 포함유무\n",
    "    \"fri\",  # 금요일 포함유무\n",
    "    \"sat\",  # 토요일 포함유무\n",
    "    \"sun\",  # 일요일 포함유무\n",
    "    \"start_time\",  # 시작시간\n",
    "    \"end_time\",  # 종료시간\n",
    "    \"etc\",  # 기타\n",
    ")\n",
    "\n",
    "review_columns = (\n",
    "    \"id\",  # 리뷰 고유번호\n",
    "    \"store\",  # 음식점 고유번호\n",
    "    \"user\",  # 유저 고유번호\n",
    "    \"score\",  # 평점\n",
    "    \"content\",  # 리뷰 내용\n",
    "    \"reg_time\",  # 리뷰 등록 시간\n",
    ")\n",
    "\n",
    "user_colums = (\n",
    "    \"id\",  # 유저 고유번호\n",
    "    \"gender\",  # 성별\n",
    "    \"born_year\"  # 태어난 해\n",
    ")\n",
    "\n",
    "\n",
    "def import_data(data_path=DATA_FILE):\n",
    "    \"\"\"\n",
    "    Req. 1-1-1 음식점 데이터 파일을 읽어서 Pandas DataFrame 형태로 저장합니다\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    try:\n",
    "        with open(data_path, encoding=\"utf-8\") as f:\n",
    "            data = json.loads(f.read())\n",
    "    except FileNotFoundError:\n",
    "        print(f\"`{data_path}` 가 존재하지 않습니다.\")\n",
    "        exit(1)\n",
    "\n",
    "    stores = []  # 음식점 테이블\n",
    "    menus = []  # 메뉴 테이블\n",
    "    hours = []  # 음식점 시간 테이블\n",
    "    reviews = []  # 리뷰 테이블\n",
    "    users = []  # 유저 테이블\n",
    "\n",
    "    for d in data:\n",
    "\n",
    "        categories = [c[\"category\"] for c in d[\"category_list\"]]\n",
    "        # review_cnt = \n",
    "        stores.append(\n",
    "            [\n",
    "                d[\"id\"],\n",
    "                d[\"name\"],\n",
    "                d[\"branch\"],\n",
    "                d[\"area\"],\n",
    "                d[\"tel\"],\n",
    "                d[\"address\"],\n",
    "                d[\"latitude\"],\n",
    "                d[\"longitude\"],\n",
    "                \"|\".join(categories),\n",
    "                d[\"review_cnt\"]\n",
    "            ]\n",
    "        )\n",
    "  \n",
    "        for menu in d[\"menu_list\"]:\n",
    "            menus.append(\n",
    "                [d[\"id\"], menu[\"menu\"], menu[\"price\"]]\n",
    "            )\n",
    "        \n",
    "        for hour in d[\"bhour_list\"]:\n",
    "            hours.append(\n",
    "                [\n",
    "                    hour[\"type\"], hour[\"week_type\"], d[\"id\"],\n",
    "                    hour[\"mon\"], hour[\"tue\"], hour[\"wed\"], hour[\"thu\"],\n",
    "                    hour[\"fri\"], hour[\"sat\"], hour[\"sun\"],\n",
    "                    hour[\"start_time\"], hour[\"end_time\"], hour[\"etc\"]\n",
    "                ]\n",
    "            )\n",
    "  \n",
    "        for review in d[\"review_list\"]:\n",
    "            r = review[\"review_info\"]\n",
    "            u = review[\"writer_info\"]\n",
    "\n",
    "            reviews.append(\n",
    "                [r[\"id\"], d[\"id\"], u[\"id\"], r[\"score\"], r[\"content\"], r[\"reg_time\"]]\n",
    "            )\n",
    "\n",
    "            users.append(\n",
    "                [u[\"id\"], u[\"gender\"], u[\"born_year\"]]\n",
    "            )\n",
    "\n",
    "    store_frame = pd.DataFrame(data=stores, columns=store_columns)\n",
    "    menu_frame = pd.DataFrame(data=menus, columns=menu_colums)\n",
    "    hour_frame = pd.DataFrame(data=hours, columns=hour_colums)\n",
    "    review_frame = pd.DataFrame(data=reviews, columns=review_columns)\n",
    "    user_frame = pd.DataFrame(data=users, columns=user_colums)\n",
    "    user_frame = user_frame.drop_duplicates()\n",
    "\n",
    "    return {\"stores\": store_frame, \"menus\": menu_frame, \"hours\": hour_frame,\n",
    "            \"reviews\": review_frame, \"users\": user_frame}\n",
    "\n",
    "\n",
    "def dump_dataframes(dataframes):\n",
    "    pd.to_pickle(dataframes, DUMP_FILE)\n",
    "\n",
    "\n",
    "def load_dataframes():\n",
    "    return pd.read_pickle(DUMP_FILE)\n",
    "\n",
    "\n",
    "print(\"[*] Parsing data...\")\n",
    "data = import_data()\n",
    "print(\"[+] Done\")\n",
    "\n",
    "print(\"[*] Dumping data...\")\n",
    "dump_dataframes(data)\n",
    "print(\"[+] Done\\n\")\n",
    "\n",
    "data = load_dataframes()\n",
    "\n",
    "term_w = shutil.get_terminal_size()[0] - 1\n",
    "separater = \"-\" * term_w\n",
    "\n",
    "# print(\"[메뉴]\")\n",
    "# print(f\"{separater}\\n\")\n",
    "# print(data[\"menus\"].head())\n",
    "# print(f\"\\n{separater}\\n\\n\")\n",
    "\n",
    "# print(\"[영업시간]\")\n",
    "# print(f\"{separater}\\n\")\n",
    "# print(data[\"hours\"].head())\n",
    "# print(f\"\\n{separater}\\n\\n\")\n",
    "\n",
    "# print(\"[리뷰]\")\n",
    "# print(f\"{separater}\\n\")\n",
    "# print(data[\"reviews\"].head())\n",
    "# print(f\"\\n{separater}\\n\\n\")\n",
    "\n",
    "# print(\"[유저]\")\n",
    "# print(f\"{separater}\\n\")\n",
    "# print(data[\"users\"].head())\n",
    "# print(f\"\\n{separater}\\n\\n\")\n",
    "\n",
    "print(data[\"menus\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "f = open(\"../data/lifestylegroupuser.pickle\", \"rb\")\n",
    "tokendata = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "data.to_dict(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가격가지고올때, 메뉴가 하나의 가게에 여러개 나오니까 그거로 평균내서 store랑 합치기\n",
    "menu = data[\"menus\"]\n",
    "menus = menu.groupby(\"store\").mean()\n",
    "# stores.to_excel(\"../data/store_big_cate.xlsx\")\n",
    "menus.to_excel(\"../data/menu_check.xlsx\")\n",
    "# menus = menu.groupby(\"store\").mean()\n",
    "print(menus.head())\n",
    "# print(menus)\n",
    "# store_new[\"store\"] = stores[\"store\"].apply(pd.to_numeric)\n",
    "# store_menu = pd.merge(store_new, menus, left_on=\"store\", right_on=\"store\")\n",
    "# print(store_menu.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_movies(movie_title, n_ratings_filter=100, n_recommendations=5):\n",
    "    similar = matrix.corrwith(matrix[movie_title])\n",
    "    corr_similar = pd.DataFrame(similar, columns=['correlation'])\n",
    "    corr_similar.dropna(inplace=True)\n",
    "    \n",
    "    orig = data.copy()\n",
    "    \n",
    "    corr_with_movie = pd.merge(\n",
    "        left=corr_similar, \n",
    "        right=orig, \n",
    "        on='title')[['title', 'correlation', 'numRatings']].drop_duplicates().reset_index(drop=True)\n",
    "    \n",
    "    result = corr_with_movie[corr_with_movie['numRatings'] > n_ratings_filter].sort_values(by='correlation', ascending=False)\n",
    "    \n",
    "    return result.head(n_recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
